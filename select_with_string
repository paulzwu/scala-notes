 val d = spark.sql("1 d1, 2 d2, 3 d3")
 d.select("d1,d2,d3".split(",").map(e=>d(e)): _*).show
 import org.apache.spark.sql._
 def myf (s: String, d: Dataset[Row]) = { s.split(",").map(e=>d(e)) }
 d.select(myf("d1,d2,d3", d):_*).show
